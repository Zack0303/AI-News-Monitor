{
  "generated_at": "2026-02-20T16:52:48.066486+00:00",
  "total_candidates": 58,
  "selected": 10,
  "run_meta": {
    "analysis_mode": "heuristic_fallback",
    "model": "heuristic",
    "fallback_used": true,
    "fallback_reason": "429 Client Error: Too Many Requests for url: https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=***",
    "top_k": 10,
    "max_rss_per_source": 8,
    "github_limit": 10
  },
  "items": [
    {
      "id": "rss::LangChain Blog::https://blog.langchain.com/on-agent-frameworks-and-agent-observability/",
      "source": "LangChain Blog",
      "title": "On Agent Frameworks and Agent Observability",
      "link": "https://blog.langchain.com/on-agent-frameworks-and-agent-observability/",
      "content": "<p>Every time LLMs get better, the same question comes back: &quot;Do you still need an agent framework?&quot; It&apos;s a fair question. The best way to build agents changes as the models get more performant and evolve, but fundamentally, the agent is a system <em>around</em> the model,</p>",
      "author": "LangChain Accounts",
      "published_at": "Fri, 13 Feb 2026 02:23:40 GMT",
      "origin_type": "rss",
      "is_relevant": true,
      "relevance_score": 81,
      "novelty_score": 71,
      "actionability_score": 52,
      "total_score": 70.8,
      "category": "ai-engineering",
      "summary_cn": "Heuristic mode summary: keyword-based relevance scoring.",
      "key_points": [],
      "output_tier": "primary"
    },
    {
      "id": "rss::Together AI Blog::https://www.together.ai/blog/together-evaluations-v2",
      "source": "Together AI Blog",
      "title": "Together Evaluations now supports comparing top commercial APIs vs. open source models",
      "link": "https://www.together.ai/blog/together-evaluations-v2",
      "content": "Together Evaluations now supports OpenAI, Anthropic, and Google models for cross-provider benchmarking. Compare open-source, fine-tuned, and proprietary models side-by-side to make data-driven decisions on quality, cost, and performanceâ€”all in one platform.",
      "author": "",
      "published_at": "Mon, 02 Feb 2026 00:00:00 GMT",
      "origin_type": "rss",
      "is_relevant": true,
      "relevance_score": 81,
      "novelty_score": 71,
      "actionability_score": 52,
      "total_score": 70.8,
      "category": "ai-engineering",
      "summary_cn": "Heuristic mode summary: keyword-based relevance scoring.",
      "key_points": [],
      "output_tier": "primary"
    },
    {
      "id": "rss::LangChain Blog::https://blog.langchain.com/customers-monday/",
      "source": "LangChain Blog",
      "title": "monday Service + LangSmith: Building a Code-First Evaluation Strategy from Day 1",
      "link": "https://blog.langchain.com/customers-monday/",
      "content": "Learn how monday Service developed an eval-driven development framework for their customer-facing service agents.",
      "author": "LangChain Accounts",
      "published_at": "Wed, 18 Feb 2026 08:05:53 GMT",
      "origin_type": "rss",
      "is_relevant": true,
      "relevance_score": 69,
      "novelty_score": 62,
      "actionability_score": 44,
      "total_score": 60.6,
      "category": "ai-engineering",
      "summary_cn": "Heuristic mode summary: keyword-based relevance scoring.",
      "key_points": [],
      "output_tier": "primary"
    },
    {
      "id": "rss::Ollama Blog::https://ollama.com/blog/gpt-oss-safeguard",
      "source": "Ollama Blog",
      "title": "OpenAI gpt-oss-safeguard",
      "link": "https://ollama.com/blog/gpt-oss-safeguard",
      "content": "Ollama is partnering with OpenAI and ROOST (Robust Open Online Safety Tools) to bring the latest gpt-oss-safeguard reasoning models to users for safety classification tasks. gpt-oss-safeguard models are available in two sizes: 20B and 120B, and are permissively licensed under the Apache 2.0 license.",
      "author": "",
      "published_at": "Wed, 29 Oct 2025 00:00:00 +0000",
      "origin_type": "rss",
      "is_relevant": true,
      "relevance_score": 69,
      "novelty_score": 62,
      "actionability_score": 44,
      "total_score": 60.6,
      "category": "ai-engineering",
      "summary_cn": "Heuristic mode summary: keyword-based relevance scoring.",
      "key_points": [],
      "output_tier": "primary"
    },
    {
      "id": "rss::Ollama Blog::https://ollama.com/blog/minimax-m2",
      "source": "Ollama Blog",
      "title": "MiniMax M2",
      "link": "https://ollama.com/blog/minimax-m2",
      "content": "MiniMax M2 is now available on Ollama's cloud. It's a model built for coding and agentic workflows.",
      "author": "",
      "published_at": "Tue, 28 Oct 2025 00:00:00 +0000",
      "origin_type": "rss",
      "is_relevant": true,
      "relevance_score": 69,
      "novelty_score": 62,
      "actionability_score": 44,
      "total_score": 60.6,
      "category": "ai-engineering",
      "summary_cn": "Heuristic mode summary: keyword-based relevance scoring.",
      "key_points": [],
      "output_tier": "primary"
    },
    {
      "id": "github::huggingface/datasets",
      "source": "GitHub Search",
      "title": "huggingface/datasets (GitHub)",
      "link": "https://github.com/huggingface/datasets",
      "content": "ðŸ¤— The largest hub of ready-to-use datasets for AI models with fast, easy-to-use and efficient data manipulation tools\nStars: 21197\nForks: 3106\nLanguage: Python\nLast push: 2026-02-18T15:18:17Z",
      "author": "huggingface",
      "published_at": "2026-02-18T15:18:17Z",
      "origin_type": "github",
      "is_relevant": true,
      "relevance_score": 61,
      "novelty_score": 62,
      "actionability_score": 44,
      "total_score": 57.0,
      "category": "ai-engineering",
      "summary_cn": "Heuristic mode summary: keyword-based relevance scoring.",
      "key_points": [],
      "output_tier": "primary"
    },
    {
      "id": "rss::Together AI Blog::https://www.together.ai/blog/what-llms-think",
      "source": "Together AI Blog",
      "title": "What do LLMs think when you don't tell them what to think about?",
      "link": "https://www.together.ai/blog/what-llms-think",
      "content": "What do language models generate when you don't tell them what to generate? New research reveals that LLM families have distinct 'knowledge priors'â€”GPT models default to code and math, Llama favors narratives, DeepSeek generates religious content, and Qwen outputs exam questions.",
      "author": "",
      "published_at": "Fri, 06 Feb 2026 00:00:00 GMT",
      "origin_type": "rss",
      "is_relevant": true,
      "relevance_score": 69,
      "novelty_score": 62,
      "actionability_score": 44,
      "total_score": 60.6,
      "category": "ai-engineering",
      "summary_cn": "Heuristic mode summary: keyword-based relevance scoring.",
      "key_points": [],
      "output_tier": "primary"
    },
    {
      "id": "rss::Together AI Blog::https://www.together.ai/blog/fine-tuning-open-llm-judges-to-outperform-gpt-5-2",
      "source": "Together AI Blog",
      "title": "Fine-tuning open LLM judges to outperform GPT-5.2",
      "link": "https://www.together.ai/blog/fine-tuning-open-llm-judges-to-outperform-gpt-5-2",
      "content": "Fine-tuned open-source LLM judges can outperform GPT-5.2 at evaluating model outputs. Using Direct Preference Optimization on just 5,400 preference pairs, we trained GPT-OSS 120B to beat GPT-5.2 on human preference alignmentâ€”at 15x lower cost and 14x faster inference speeds.",
      "author": "",
      "published_at": "Mon, 02 Feb 2026 00:00:00 GMT",
      "origin_type": "rss",
      "is_relevant": true,
      "relevance_score": 69,
      "novelty_score": 62,
      "actionability_score": 44,
      "total_score": 60.6,
      "category": "ai-engineering",
      "summary_cn": "Heuristic mode summary: keyword-based relevance scoring.",
      "key_points": [],
      "output_tier": "primary"
    },
    {
      "id": "rss::OpenAI Blog::https://openai.com/index/scaling-social-science-research",
      "source": "OpenAI Blog",
      "title": "Scaling social science research",
      "link": "https://openai.com/index/scaling-social-science-research",
      "content": "GABRIEL is a new open-source toolkit from OpenAI that uses GPT to turn qualitative text and images into quantitative data, helping social scientists analyze research at scale.",
      "author": "",
      "published_at": "Fri, 13 Feb 2026 09:00:00 GMT",
      "origin_type": "rss",
      "is_relevant": true,
      "relevance_score": 57,
      "novelty_score": 53,
      "actionability_score": 36,
      "total_score": 50.5,
      "category": "ai-engineering",
      "summary_cn": "Heuristic mode summary: keyword-based relevance scoring.",
      "key_points": [],
      "output_tier": "primary"
    },
    {
      "id": "rss::OpenAI Blog::https://openai.com/index/introducing-gpt-5-3-codex-spark",
      "source": "OpenAI Blog",
      "title": "Introducing GPT-5.3-Codex-Spark",
      "link": "https://openai.com/index/introducing-gpt-5-3-codex-spark",
      "content": "Introducing GPT-5.3-Codex-Sparkâ€”our first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.",
      "author": "",
      "published_at": "Thu, 12 Feb 2026 10:00:00 GMT",
      "origin_type": "rss",
      "is_relevant": true,
      "relevance_score": 57,
      "novelty_score": 53,
      "actionability_score": 36,
      "total_score": 50.5,
      "category": "ai-engineering",
      "summary_cn": "Heuristic mode summary: keyword-based relevance scoring.",
      "key_points": [],
      "output_tier": "primary"
    }
  ]
}