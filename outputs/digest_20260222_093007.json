{
  "generated_at": "2026-02-22T09:30:07.942197+00:00",
  "total_candidates": 58,
  "selected": 12,
  "run_meta": {
    "analysis_mode": "llm_gemini",
    "model": "gemini-2.0-flash",
    "fallback_used": false,
    "fallback_reason": "",
    "llm_provider_attempted": "gemini",
    "llm_attempts": 10,
    "llm_batch_size": 6,
    "llm_max_retries": 2,
    "top_k": 12,
    "max_rss_per_source": 8,
    "github_limit": 10
  },
  "items": [
    {
      "id": "rss::LangChain Blog::https://blog.langchain.com/improving-deep-agents-with-harness-engineering/",
      "source": "LangChain Blog",
      "title": "Improving Deep Agents with harness engineering",
      "link": "https://blog.langchain.com/improving-deep-agents-with-harness-engineering/",
      "content": "<p>TLDR: Our coding agent went from Top 30 to Top 5 on <a href=\"https://www.tbench.ai/leaderboard/terminal-bench/2.0?ref=blog.langchain.com\">Terminal Bench 2.0</a>. We only changed the harness. Here&#x2019;s our approach to harness engineering (teaser: self-verification &amp; tracing help a lot).</p><h2 id=\"the-goal-of-harness-engineering\">The Goal of Harness Engineering</h2><p>The goal of a harness is to mold the</p>",
      "author": "LangChain Accounts",
      "published_at": "Tue, 17 Feb 2026 16:15:28 GMT",
      "origin_type": "rss",
      "is_relevant": true,
      "relevance_score": 95,
      "novelty_score": 85,
      "actionability_score": 90,
      "total_score": 90.8,
      "category": "Agent Performance",
      "summary_cn": "通过改进harness，编码Agent在Terminal Bench 2.0上的排名从前30提升到前5。重点是自验证和追踪。",
      "key_points": [
        "harness工程",
        "Agent性能提升",
        "自验证",
        "追踪"
      ],
      "why_it_matters": "展示harness工程的力量",
      "next_action": "研究harness工程的方法",
      "preference_score": 0.0,
      "personalized_total_score": 90.8,
      "preference_reasons": [],
      "output_tier": "primary"
    },
    {
      "id": "rss::Ollama Blog::https://ollama.com/blog/openclaw",
      "source": "Ollama Blog",
      "title": "OpenClaw",
      "link": "https://ollama.com/blog/openclaw",
      "content": "OpenClaw is a personal AI assistant that connects your messaging apps to local AI coding agents, all running on your own device.",
      "author": "",
      "published_at": "Sun, 01 Feb 2026 00:00:00 +0000",
      "origin_type": "rss",
      "is_relevant": true,
      "relevance_score": 95,
      "novelty_score": 85,
      "actionability_score": 90,
      "total_score": 90.8,
      "category": "AI Assistant",
      "summary_cn": "OpenClaw是一个个人AI助手，可将消息应用程序连接到本地AI编码代理，所有这些都在您自己的设备上运行。",
      "key_points": [
        "个人AI助手。",
        "连接消息应用程序。",
        "本地AI编码代理。",
        "设备上运行。"
      ],
      "why_it_matters": "本地AI助手，保护隐私",
      "next_action": "评估OpenClaw在实际场景的应用",
      "preference_score": 0.0,
      "personalized_total_score": 90.8,
      "preference_reasons": [],
      "output_tier": "primary"
    },
    {
      "id": "rss::Together AI Blog::https://www.together.ai/blog/fine-tuning-open-llm-judges-to-outperform-gpt-5-2",
      "source": "Together AI Blog",
      "title": "Fine-tuning open LLM judges to outperform GPT-5.2",
      "link": "https://www.together.ai/blog/fine-tuning-open-llm-judges-to-outperform-gpt-5-2",
      "content": "Fine-tuned open-source LLM judges can outperform GPT-5.2 at evaluating model outputs. Using Direct Preference Optimization on just 5,400 preference pairs, we trained GPT-OSS 120B to beat GPT-5.2 on human preference alignment—at 15x lower cost and 14x faster inference speeds.",
      "author": "",
      "published_at": "Mon, 02 Feb 2026 00:00:00 GMT",
      "origin_type": "rss",
      "is_relevant": true,
      "relevance_score": 95,
      "novelty_score": 90,
      "actionability_score": 80,
      "total_score": 89.8,
      "category": "AI Models",
      "summary_cn": "微调开源 LLM 评判模型，性能优于 GPT-5.2。",
      "key_points": [
        "GPT-OSS 120B超越GPT-5.2",
        "Direct Preference Optimization",
        "成本降低15倍"
      ],
      "why_it_matters": "开源模型潜力大",
      "next_action": "研究微调方法和结果",
      "preference_score": 0.0,
      "personalized_total_score": 89.8,
      "preference_reasons": [],
      "output_tier": "primary"
    },
    {
      "id": "rss::LangChain Blog::https://blog.langchain.com/new-in-agent-builder-all-new-agent-chat-file-uploads-tool-registry/",
      "source": "LangChain Blog",
      "title": "New in Agent Builder: all new agent chat, file uploads + tool registry",
      "link": "https://blog.langchain.com/new-in-agent-builder-all-new-agent-chat-file-uploads-tool-registry/",
      "content": "<p>Today, we&apos;re expanding what you can do with <a href=\"https://www.langchain.com/langsmith/agent-builder?ref=blog.langchain.com\">LangSmith Agent Builder</a>. It&#x2019;s an big update built around a simple idea: working with an agent should feel like working with a teammate.</p><p>We rebuilt Agent Builder around this idea. There is now an always available agent (&#x201d;</p>",
      "author": "LangChain Accounts",
      "published_at": "Wed, 18 Feb 2026 15:55:08 GMT",
      "origin_type": "rss",
      "is_relevant": true,
      "relevance_score": 90,
      "novelty_score": 80,
      "actionability_score": 95,
      "total_score": 88.2,
      "category": "Agent Development",
      "summary_cn": "LangSmith Agent Builder更新，重点围绕与Agent协作如与队友协作的理念，包括Agent聊天、文件上传和工具注册。",
      "key_points": [
        "Agent Builder更新",
        "Agent聊天功能",
        "文件上传功能",
        "工具注册功能"
      ],
      "why_it_matters": "提升Agent协作体验",
      "next_action": "体验新版Agent Builder",
      "preference_score": 0.0,
      "personalized_total_score": 88.2,
      "preference_reasons": [],
      "output_tier": "primary"
    },
    {
      "id": "rss::Together AI Blog::https://www.together.ai/blog/consistency-diffusion-language-models",
      "source": "Together AI Blog",
      "title": "Consistency diffusion language models: Up to 14x faster inference without sacrificing quality",
      "link": "https://www.together.ai/blog/consistency-diffusion-language-models",
      "content": "Standard diffusion language models can't use KV caching and need too many refinement steps to be practical. CDLM fixes both with a post-training recipe that enables exact block-wise KV caching and trajectory-consistent step reduction — delivering up to 14.5x latency improvements",
      "author": "",
      "published_at": "Thu, 19 Feb 2026 00:00:00 GMT",
      "origin_type": "rss",
      "is_relevant": true,
      "relevance_score": 95,
      "novelty_score": 85,
      "actionability_score": 80,
      "total_score": 88.2,
      "category": "AI Optimization",
      "summary_cn": "一致性扩散语言模型（CDLM）通过后训练方法，实现高达14倍的推理速度提升，且不牺牲质量。",
      "key_points": [
        "Standard diffusion models lack KV caching.",
        "CDLM enables block-wise KV caching.",
        "CDLM enables trajectory-consistent step reduction.",
        "Up to 14.5x latency improvements."
      ],
      "why_it_matters": "显著提升推理速度和效率",
      "next_action": "评估CDLM在实际应用中的性能",
      "preference_score": 0.0,
      "personalized_total_score": 88.2,
      "preference_reasons": [],
      "output_tier": "primary"
    },
    {
      "id": "rss::LangChain Blog::https://blog.langchain.com/how-we-built-agent-builders-memory-system/",
      "source": "LangChain Blog",
      "title": "How we built Agent Builder’s memory system",
      "link": "https://blog.langchain.com/how-we-built-agent-builders-memory-system/",
      "content": "A key part of Agent Builder is its memory system. In this article we cover our rationale for prioritizing a memory system, technical details of how we built it, learnings from building the memory system, what the memory system enables, and discuss future work.",
      "author": "LangChain Accounts",
      "published_at": "Sun, 22 Feb 2026 03:55:36 GMT",
      "origin_type": "rss",
      "is_relevant": true,
      "relevance_score": 90,
      "novelty_score": 85,
      "actionability_score": 80,
      "total_score": 86.0,
      "category": "AI Agents",
      "summary_cn": "Agent Builder的记忆系统构建方法。",
      "key_points": [
        "Agent Builder",
        "记忆系统",
        "LangChain",
        "AI Agents"
      ],
      "why_it_matters": "Agent记忆的关键技术",
      "next_action": "研究Agent Builder记忆系统",
      "preference_score": 0.0,
      "personalized_total_score": 86.0,
      "preference_reasons": [],
      "output_tier": "primary"
    },
    {
      "id": "github::Significant-Gravitas/AutoGPT",
      "source": "GitHub Search",
      "title": "Significant-Gravitas/AutoGPT (GitHub)",
      "link": "https://github.com/Significant-Gravitas/AutoGPT",
      "content": "AutoGPT is the vision of accessible AI for everyone, to use and to build on. Our mission is to provide the tools, so that you can focus on what matters.\nStars: 181925\nForks: 46226\nLanguage: Python\nLast push: 2026-02-22T09:25:32Z",
      "author": "Significant-Gravitas",
      "published_at": "2026-02-22T09:25:32Z",
      "origin_type": "github",
      "is_relevant": true,
      "relevance_score": 95,
      "novelty_score": 80,
      "actionability_score": 75,
      "total_score": 85.5,
      "category": "AI Agents",
      "summary_cn": "AutoGPT是一个开源项目，旨在为每个人提供易于访问和构建的AI工具。",
      "key_points": [
        "旨在提供可访问的AI工具",
        "开源项目",
        "使用Python语言开发"
      ],
      "why_it_matters": "推动AI的普及和应用",
      "next_action": "评估AutoGPT在特定场景下的应用",
      "preference_score": 0.0,
      "personalized_total_score": 85.5,
      "preference_reasons": [],
      "output_tier": "primary"
    },
    {
      "id": "github::marimo-team/marimo",
      "source": "GitHub Search",
      "title": "marimo-team/marimo (GitHub)",
      "link": "https://github.com/marimo-team/marimo",
      "content": "A reactive notebook for Python — run reproducible experiments, query with SQL, execute as a script, deploy as an app, and version with git. Stored as pure Python. All in a modern, AI-native editor.\nStars: 19260\nForks: 927\nLanguage: Python\nLast push: 2026-02-22T04:54:06Z",
      "author": "marimo-team",
      "published_at": "2026-02-22T04:54:06Z",
      "origin_type": "github",
      "is_relevant": true,
      "relevance_score": 80,
      "novelty_score": 85,
      "actionability_score": 70,
      "total_score": 79.0,
      "category": "AI Development",
      "summary_cn": "Marimo是一个响应式Python笔记本，支持实验、查询、脚本和部署。",
      "key_points": [
        "响应式Python笔记本",
        "支持SQL查询",
        "可作为脚本和应用部署"
      ],
      "why_it_matters": "简化AI应用开发和部署。",
      "next_action": "试用Marimo，评估开发效率。",
      "preference_score": 0.0,
      "personalized_total_score": 79.0,
      "preference_reasons": [],
      "output_tier": "primary"
    },
    {
      "id": "github::onnx/onnx",
      "source": "GitHub Search",
      "title": "onnx/onnx (GitHub)",
      "link": "https://github.com/onnx/onnx",
      "content": "Open standard for machine learning interoperability\nStars: 20366\nForks: 3874\nLanguage: Python\nLast push: 2026-02-22T06:35:30Z",
      "author": "onnx",
      "published_at": "2026-02-22T06:35:30Z",
      "origin_type": "github",
      "is_relevant": true,
      "relevance_score": 90,
      "novelty_score": 60,
      "actionability_score": 80,
      "total_score": 78.5,
      "category": "Machine Learning",
      "summary_cn": "ONNX是机器学习互操作性的开放标准。",
      "key_points": [
        "机器学习互操作性",
        "开放标准",
        "Python语言"
      ],
      "why_it_matters": "促进不同框架模型互操作。",
      "next_action": "研究ONNX标准，评估兼容性。",
      "preference_score": 0.0,
      "personalized_total_score": 78.5,
      "preference_reasons": [],
      "output_tier": "primary"
    },
    {
      "id": "rss::Together AI Blog::https://www.together.ai/blog/dedicated-container-inference",
      "source": "Together AI Blog",
      "title": "Introducing Dedicated Container Inference:  Delivering 2.6x faster inference for custom AI models",
      "link": "https://www.together.ai/blog/dedicated-container-inference",
      "content": "Together AI launches Dedicated Container Inference — production-grade orchestration for custom AI models with 1.4x–2.6x faster inference.",
      "author": "",
      "published_at": "Thu, 12 Feb 2026 00:00:00 GMT",
      "origin_type": "rss",
      "is_relevant": true,
      "relevance_score": 90,
      "novelty_score": 80,
      "actionability_score": 85,
      "total_score": 85.8,
      "category": "AI Infrastructure",
      "summary_cn": "Together AI推出专用容器推理，为定制AI模型提供生产级编排，推理速度提高1.4x–2.6x。",
      "key_points": [
        "Dedicated Container Inference launched.",
        "Production-grade orchestration for custom AI models.",
        "1.4x–2.6x faster inference."
      ],
      "why_it_matters": "加速定制模型推理，提升效率",
      "next_action": "了解专用容器推理的部署方法",
      "preference_score": 0.0,
      "personalized_total_score": 85.8,
      "preference_reasons": [],
      "output_tier": "primary"
    },
    {
      "id": "rss::OpenAI Blog::https://openai.com/index/introducing-gpt-5-3-codex-spark",
      "source": "OpenAI Blog",
      "title": "Introducing GPT-5.3-Codex-Spark",
      "link": "https://openai.com/index/introducing-gpt-5-3-codex-spark",
      "content": "Introducing GPT-5.3-Codex-Spark—our first real-time coding model. 15x faster generation, 128k context, now in research preview for ChatGPT Pro users.",
      "author": "",
      "published_at": "Thu, 12 Feb 2026 10:00:00 GMT",
      "origin_type": "rss",
      "is_relevant": true,
      "relevance_score": 95,
      "novelty_score": 80,
      "actionability_score": 75,
      "total_score": 85.5,
      "category": "AI Models",
      "summary_cn": "OpenAI推出了GPT-5.3-Codex-Spark，这是他们的第一个实时编码模型。生成速度快15倍，上下文为128k，目前正在为ChatGPT Pro用户进行研究预览。",
      "key_points": [
        "GPT-5.3-Codex-Spark",
        "实时编码模型",
        "15倍速度提升",
        "128k上下文",
        "ChatGPT Pro"
      ],
      "why_it_matters": "编码效率大幅提升，降低开发成本",
      "next_action": "评估GPT-5.3-Codex-Spark的性能",
      "preference_score": 0.0,
      "personalized_total_score": 85.5,
      "preference_reasons": [],
      "output_tier": "primary"
    },
    {
      "id": "rss::OpenAI Blog::https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt",
      "source": "OpenAI Blog",
      "title": "Introducing Lockdown Mode and Elevated Risk labels in ChatGPT",
      "link": "https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt",
      "content": "Introducing Lockdown Mode and Elevated Risk labels in ChatGPT to help organizations defend against prompt injection and AI-driven data exfiltration.",
      "author": "",
      "published_at": "Fri, 13 Feb 2026 10:00:00 GMT",
      "origin_type": "rss",
      "is_relevant": true,
      "relevance_score": 90,
      "novelty_score": 75,
      "actionability_score": 85,
      "total_score": 84.2,
      "category": "AI Security",
      "summary_cn": "ChatGPT引入锁定模式和高风险标签，以帮助组织防御提示注入和AI驱动的数据泄露。",
      "key_points": [
        "引入锁定模式",
        "引入高风险标签",
        "防御提示注入和数据泄露"
      ],
      "why_it_matters": "增强ChatGPT的安全性",
      "next_action": "评估锁定模式的有效性",
      "preference_score": 0.0,
      "personalized_total_score": 84.2,
      "preference_reasons": [],
      "output_tier": "primary"
    }
  ]
}